# ML-EX-Python
These are Exercises for Coursera's MachineLearning (by Andrew Ng) by Python.

## Image of EX-example



### ex1
#### ex1_1 Linear regression with one variable
![image_ex1_1](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex1_1.png)
</br>
</br>
</br>
#### ex1_2 Visualizing J(θ) (Surface)  
![image_ex1_2](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex1_2.png)
</br>
</br>
</br>
#### ex1_2 Visualizing J(θ) (Contour)
![image_ex1_3](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex1_3.png)
</br>
</br>
</br>
#### ex1_multi_1 Linear regression with multiple variables
Convergence of gradient descent with an appropriate learning rate
![image_ex1_multi_1](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex1_multi_1.png)
 
---
### ex2
#### ex2_1 Logistic Regression
![image_ex2_1](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex2_1.png)
</br>
</br>
</br>
#### ex2_2 Logistic Regression
Training data with decision boundary
![image_ex2_2](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex2_2.png)
</br>
</br>
</br>
#### ex2_LR_1 Regularized Logistic Regression
![image_ex2_LR_1](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex2_LR_1.png)
</br>
</br>
</br>
#### ex2_LR_2 Regularized Logistic Regression
Training data with decision boundary (λ = 1)
![image_ex2_LR_2](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex2_LR_2.png)
 
---
### ex3
#### ex3_1 Multi-class Classification(MNIST)
![image_ex3_1](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex3_1.png)

 
---
### ex5
#### ex5_1 Polynomial Regression Fit
![image_ex5_1](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex5_1.png)
</br>
</br>
</br>
#### ex5_2 Polynomial Regression Learning Curve
![image_ex5_2](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex5_2.png)
</br>
</br>
</br>
#### ex5_3 Regularization and Bias/Variance
![image_ex5_3](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex5_3.png)

 
---
### ex6
#### ex6_1 SVM Decision Boundary with C = 1
![image_ex6_1](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex6_1.png)
</br>
</br>
</br>
#### ex6_2  SVM (Gaussian Kernel) Decision Boundary (Example Dataset 2)
![image_ex6_2](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex6_2.png)
</br>
</br>
</br>
#### ex6_3  SVM (Gaussian Kernel) Decision Boundary (Example Dataset 3)
![image_ex6_3](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex6_3.png)


---
### ex7
#### ex7_1 K-means on example dataset
![image_ex7_1](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex7_1.png)
</br>
</br>
</br>
#### ex7_2  Original and reconstructed image (when using K-means to compress the image)
![image_ex7_2](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex7_2.png)
</br>
</br>
</br>
#### ex7_3  PCA - Computed eigenvectors of the dataset
![image_ex7_3](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex7_3.png)
</br>
</br>
</br>
#### ex7_4  The normalized and projected data after PCA
![image_ex7_4](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex7_4.png)
</br>
</br>
</br>
#### ex7_5  Original images of faces and ones reconstructed from only the top 100 principal components
![image_ex7_5](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex7_5.png)
</br>
</br>
</br>
#### ex7_6  PCA for visualization - 3D
![image_ex7_6](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex7_6.png)
</br>
</br>
</br>
#### ex7_7  2D visualization produced using PCA
![image_ex7_7](https://github.com/X-21/ML-EX-Python/blob/master/doc/image/ex7_7.png)



</br>